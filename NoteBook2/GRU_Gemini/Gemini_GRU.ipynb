{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47520219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.graph_objects as go\n",
    "import optuna\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "# Ignorar advertencias de Optuna y otras\n",
    "warnings.filterwarnings('ignore', category=optuna.exceptions.ExperimentalWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Configuración del dispositivo (GPU o CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d395290e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados y preparados:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3680 entries, 2014-12-29 to 2022-01-03\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                3680 non-null   object \n",
      " 1   id_bar            3680 non-null   int64  \n",
      " 2   anio              3680 non-null   int64  \n",
      " 3   semana            3680 non-null   UInt32 \n",
      " 4   ESTRATO           3680 non-null   float64\n",
      " 5   area_barrio       3680 non-null   float64\n",
      " 6   dengue            3680 non-null   float64\n",
      " 7   concentraciones   3680 non-null   float64\n",
      " 8   vivienda          3680 non-null   float64\n",
      " 9   equipesado        3680 non-null   float64\n",
      " 10  sumideros         3680 non-null   float64\n",
      " 11  maquina           3680 non-null   float64\n",
      " 12  lluvia_mean       3680 non-null   float64\n",
      " 13  lluvia_var        3680 non-null   float64\n",
      " 14  lluvia_max        3680 non-null   float64\n",
      " 15  temperatura_mean  3680 non-null   float64\n",
      " 16  temperatura_var   3680 non-null   float64\n",
      " 17  temperatura_max   3680 non-null   float64\n",
      " 18  temperatura_min   3680 non-null   float64\n",
      "dtypes: UInt32(1), float64(15), int64(2), object(1)\n",
      "memory usage: 564.2+ KB\n",
      "None\n",
      "                   id  id_bar  anio  semana  ESTRATO  area_barrio  dengue  \\\n",
      "fecha                                                                       \n",
      "2014-12-29  4_2015_01       4  2015       1      3.0        0.560     0.0   \n",
      "2014-12-29  5_2015_01       5  2015       1      3.0        0.842     0.0   \n",
      "2014-12-29  3_2015_01       3  2015       1      1.0        0.781     0.0   \n",
      "2014-12-29  8_2015_01       8  2015       1      2.0        0.394     0.0   \n",
      "2014-12-29  9_2015_01       9  2015       1      2.0        0.292     0.0   \n",
      "\n",
      "            concentraciones  vivienda  equipesado  sumideros  maquina  \\\n",
      "fecha                                                                   \n",
      "2014-12-29              0.0       0.0         0.0        0.0      0.0   \n",
      "2014-12-29              0.0       0.0         0.0        0.0      0.0   \n",
      "2014-12-29              0.0       0.0         0.0        0.0      0.0   \n",
      "2014-12-29              0.0       0.0         0.0        0.0      0.0   \n",
      "2014-12-29              0.0       0.0         0.0        0.0      0.0   \n",
      "\n",
      "            lluvia_mean  lluvia_var  lluvia_max  temperatura_mean  \\\n",
      "fecha                                                               \n",
      "2014-12-29     0.000651    0.000041      0.0625         26.163889   \n",
      "2014-12-29     0.000651    0.000041      0.0625         26.163889   \n",
      "2014-12-29     0.000651    0.000041      0.0625         26.163889   \n",
      "2014-12-29     0.000651    0.000041      0.0625         26.163889   \n",
      "2014-12-29     0.000651    0.000041      0.0625         26.163889   \n",
      "\n",
      "            temperatura_var  temperatura_max  temperatura_min  \n",
      "fecha                                                          \n",
      "2014-12-29        11.588928             31.8             20.9  \n",
      "2014-12-29        11.588928             31.8             20.9  \n",
      "2014-12-29        11.588928             31.8             20.9  \n",
      "2014-12-29        11.588928             31.8             20.9  \n",
      "2014-12-29        11.588928             31.8             20.9  \n"
     ]
    }
   ],
   "source": [
    "# Carga de datos\n",
    "df = pd.read_parquet('../../Datos/df_train.parquet')\n",
    "\n",
    "df = df.drop(columns=['lluvia_min'])\n",
    "\n",
    "# Crear columna de fecha a partir de año y semana ISO\n",
    "# %G: Año ISO, %V: Semana ISO, %u: Día de la semana (1=Lunes)\n",
    "df['fecha'] = pd.to_datetime(df['anio'].astype(str) + df['semana'].astype(str) + '1', format='%G%V%u')\n",
    "\n",
    "# Establecer la fecha como índice y ordenar\n",
    "df = df.set_index('fecha').sort_index()\n",
    "\n",
    "print(\"Datos cargados y preparados:\")\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0ab0ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del set de Entrenamiento: (3150, 19)\n",
      "Tamaño del set de Validación: (530, 19)\n",
      "\n",
      "Preprocesamiento completado.\n",
      "Columnas categóricas: ['id_bar', 'ESTRATO']\n",
      "Columnas numéricas escaladas: ['area_barrio', 'dengue', 'concentraciones', 'vivienda', 'equipesado', 'sumideros', 'maquina', 'lluvia_mean', 'lluvia_var', 'lluvia_max', 'temperatura_mean', 'temperatura_var', 'temperatura_max', 'temperatura_min']\n"
     ]
    }
   ],
   "source": [
    "# --- División de Datos ---\n",
    "# Creamos una copia para evitar advertencias de SettingWithCopyWarning\n",
    "df_train_val = df[df['anio'] <= 2021].copy()\n",
    "df_forecast_inputs = df.copy() # Copia completa para la fase de pronóstico\n",
    "\n",
    "# --- Tratamiento de Variables Categóricas (para Embeddings) ---\n",
    "# PRIMERO, convertimos las columnas a tipo 'category' en el DataFrame base\n",
    "categorical_cols = ['id_bar', 'ESTRATO']\n",
    "for col in categorical_cols:\n",
    "    df_train_val[col] = df_train_val[col].astype('category')\n",
    "\n",
    "# SEGUNDO, creamos los mapeos a partir del DataFrame con el tipo ya convertido\n",
    "cat_mappings = {col: {cat: i for i, cat in enumerate(df_train_val[col].cat.categories)} for col in categorical_cols}\n",
    "\n",
    "# TERCERO, ahora creamos los dataframes de entrenamiento y validación\n",
    "# Estos heredarán el tipo 'category' de df_train_val\n",
    "train_df = df_train_val[df_train_val['anio'] < 2021].copy()\n",
    "val_df = df_train_val[df_train_val['anio'] == 2021].copy()\n",
    "\n",
    "# AHORA SÍ, aplicamos .cat.codes a las columnas que ya son de tipo categórico\n",
    "for col in categorical_cols:\n",
    "    train_df[col] = train_df[col].cat.codes\n",
    "    val_df[col] = val_df[col].cat.codes\n",
    "\n",
    "print(f\"Tamaño del set de Entrenamiento: {train_df.shape}\")\n",
    "print(f\"Tamaño del set de Validación: {val_df.shape}\")\n",
    "\n",
    "# --- Escalado de Variables Numéricas ---\n",
    "target_col = 'dengue'\n",
    "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "# Quitar las columnas que no son covariables\n",
    "for col in ['anio', 'semana'] + categorical_cols:\n",
    "    if col in numerical_cols:\n",
    "        numerical_cols.remove(col)\n",
    "        \n",
    "# El objetivo 'dengue' también se escala\n",
    "numerical_features_to_scale = numerical_cols.copy()\n",
    "if target_col not in numerical_features_to_scale:\n",
    "    numerical_features_to_scale.append(target_col)\n",
    "\n",
    "# Ajustar el escalador SÓLO con datos de entrenamiento\n",
    "scaler = StandardScaler()\n",
    "# Usamos .loc para asegurar la asignación correcta y evitar advertencias\n",
    "train_df.loc[:, numerical_features_to_scale] = scaler.fit_transform(train_df[numerical_features_to_scale])\n",
    "\n",
    "# Transformar los conjuntos de validación con el mismo escalador\n",
    "val_df.loc[:, numerical_features_to_scale] = scaler.transform(val_df[numerical_features_to_scale])\n",
    "\n",
    "\n",
    "# --- Creación de Secuencias (Ventanas Deslizantes) ---\n",
    "def create_sequences(data, window_size, target_col, categorical_cols, numerical_cols):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    # Agrupar por cada serie temporal individual (cada barrio)\n",
    "    for id_bar_code, group in data.groupby('id_bar'):\n",
    "        # Usamos las columnas numéricas que ya fueron escaladas y las categóricas ya codificadas\n",
    "        feature_data = group[categorical_cols + numerical_cols].values\n",
    "        target_data = group[target_col].values\n",
    "        \n",
    "        for i in range(len(group) - window_size):\n",
    "            sequences.append(feature_data[i:i + window_size])\n",
    "            labels.append(target_data[i + window_size])\n",
    "            \n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "# Indices de las columnas para separar en el modelo\n",
    "all_feature_cols = categorical_cols + numerical_cols\n",
    "cat_indices = [i for i, col in enumerate(all_feature_cols) if col in categorical_cols]\n",
    "num_indices = [i for i, col in enumerate(all_feature_cols) if col in numerical_cols]\n",
    "\n",
    "print(\"\\nPreprocesamiento completado.\")\n",
    "print(f\"Columnas categóricas: {categorical_cols}\")\n",
    "print(f\"Columnas numéricas escaladas: {numerical_features_to_scale}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b8cd3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding para 'id_bar': 10 categorías, dim=5\n",
      "Embedding para 'ESTRATO': 3 categorías, dim=2\n"
     ]
    }
   ],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, embedding_sizes, n_continuous, hidden_size, num_layers, dropout_rate, output_size=1):\n",
    "        super(GRUModel, self).__init__()\n",
    "        \n",
    "        # Capas de Embedding para variables categóricas\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(num_categories, embed_dim) for num_categories, embed_dim in embedding_sizes])\n",
    "        \n",
    "        n_embedding_dims = sum(embed_dim for _, embed_dim in embedding_sizes)\n",
    "        \n",
    "        # Capa GRU\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=n_embedding_dims + n_continuous,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout_rate if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Capa de salida\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        # Procesar embeddings\n",
    "        x_embedded = [embedding(x_cat[:, :, i]) for i, embedding in enumerate(self.embeddings)]\n",
    "        x_embedded = torch.cat(x_embedded, dim=2)\n",
    "        \n",
    "        # Concatenar embeddings con características continuas\n",
    "        x = torch.cat([x_embedded, x_cont], dim=2)\n",
    "        \n",
    "        # Pasar por la GRU\n",
    "        # output shape: (batch_size, seq_len, hidden_size)\n",
    "        # hidden shape: (num_layers, batch_size, hidden_size)\n",
    "        output, _ = self.gru(x)\n",
    "        \n",
    "        # Tomar la salida del último paso de tiempo\n",
    "        last_output = output[:, -1, :]\n",
    "        last_output = self.dropout(last_output)\n",
    "        \n",
    "        # Pasar por la capa lineal final\n",
    "        out = self.fc(last_output)\n",
    "        return out\n",
    "\n",
    "# Tamaños de los embeddings (regla general: min(50, num_categorias/2))\n",
    "embedding_sizes = []\n",
    "for col in categorical_cols:\n",
    "    num_categories = len(cat_mappings[col])\n",
    "    embed_dim = min(50, (num_categories + 1) // 2)\n",
    "    embedding_sizes.append((num_categories, embed_dim))\n",
    "    print(f\"Embedding para '{col}': {num_categories} categorías, dim={embed_dim}\")\n",
    "\n",
    "n_continuous = len(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0966b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # --- Definir espacio de búsqueda de hiperparámetros ---\n",
    "    window_size = trial.suggest_int('window_size', 8, 52)\n",
    "    hidden_size = trial.suggest_categorical('hidden_size', [16, 32, 64, 128])\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "\n",
    "    # --- Crear secuencias y DataLoaders para este trial ---\n",
    "    all_cols = categorical_cols + numerical_cols\n",
    "    X_train_seq, y_train_seq = create_sequences(train_df, window_size, target_col, categorical_cols, numerical_cols)\n",
    "    X_val_seq, y_val_seq = create_sequences(val_df, window_size, target_col, categorical_cols, numerical_cols)\n",
    "\n",
    "    # Convertir a tensores\n",
    "    X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train_seq, dtype=torch.float32).view(-1, 1)\n",
    "    X_val_tensor = torch.tensor(X_val_seq, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val_seq, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    # Crear Datasets y DataLoaders\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # --- Instanciar y entrenar modelo ---\n",
    "    model = GRUModel(embedding_sizes, n_continuous, hidden_size, num_layers, dropout_rate).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Bucle de entrenamiento\n",
    "    num_epochs = 200\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for sequences, labels in train_loader:\n",
    "            sequences = sequences.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            x_cat = sequences[:, :, cat_indices].long()\n",
    "            x_cont = sequences[:, :, num_indices].float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_cat, x_cont)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # --- Evaluación ---\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in val_loader:\n",
    "            sequences = sequences.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            x_cat = sequences[:, :, cat_indices].long()\n",
    "            x_cont = sequences[:, :, num_indices].float()\n",
    "            \n",
    "            outputs = model(x_cat, x_cont)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    # Optuna puede usar este valor para podar trials no prometedores (pruning)\n",
    "    trial.report(avg_val_loss, epoch)\n",
    "    if trial.should_prune():\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    return avg_val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f021c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 15:01:01,199] A new study created in memory with name: no-name-1d15bda6-0cf4-4724-baab-de318e7afac6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a09ce5a7494b33ad940f222a00027b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-23 15:01:22,573] Trial 0 finished with value: 0.08618620907266934 and parameters: {'window_size': 37, 'hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.44365750535906623, 'learning_rate': 0.007306199442475917, 'batch_size': 64}. Best is trial 0 with value: 0.08618620907266934.\n",
      "[I 2025-06-23 15:02:44,309] Trial 1 finished with value: 0.2502003490924835 and parameters: {'window_size': 14, 'hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.18129529945655665, 'learning_rate': 0.00012652675320423551, 'batch_size': 16}. Best is trial 0 with value: 0.08618620907266934.\n",
      "[I 2025-06-23 15:03:18,827] Trial 2 finished with value: 0.16794285391058242 and parameters: {'window_size': 32, 'hidden_size': 16, 'num_layers': 1, 'dropout_rate': 0.24797569606260328, 'learning_rate': 0.00626973198836374, 'batch_size': 32}. Best is trial 0 with value: 0.08618620907266934.\n",
      "[I 2025-06-23 15:03:58,853] Trial 3 finished with value: 0.1057263407856226 and parameters: {'window_size': 30, 'hidden_size': 16, 'num_layers': 2, 'dropout_rate': 0.18283444083955824, 'learning_rate': 0.0007114690778056103, 'batch_size': 32}. Best is trial 0 with value: 0.08618620907266934.\n",
      "[I 2025-06-23 15:04:41,405] Trial 4 finished with value: 0.09810599791152137 and parameters: {'window_size': 33, 'hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0.36748137674348924, 'learning_rate': 0.0002589961251615156, 'batch_size': 32}. Best is trial 0 with value: 0.08618620907266934.\n",
      "[I 2025-06-23 15:05:03,999] Trial 5 pruned. \n",
      "[I 2025-06-23 15:05:22,917] Trial 6 finished with value: 0.06909781927242875 and parameters: {'window_size': 32, 'hidden_size': 16, 'num_layers': 1, 'dropout_rate': 0.33852658404299696, 'learning_rate': 0.009728989240744546, 'batch_size': 64}. Best is trial 6 with value: 0.06909781927242875.\n",
      "[I 2025-06-23 15:05:46,683] Trial 7 pruned. \n",
      "[I 2025-06-23 15:07:09,903] Trial 8 pruned. \n",
      "[I 2025-06-23 15:07:38,524] Trial 9 pruned. \n",
      "[I 2025-06-23 15:07:56,894] Trial 10 pruned. \n",
      "[I 2025-06-23 15:08:20,512] Trial 11 pruned. \n",
      "[I 2025-06-23 15:08:40,593] Trial 12 pruned. \n",
      "[I 2025-06-23 15:08:54,527] Trial 13 finished with value: 0.07652835547924042 and parameters: {'window_size': 38, 'hidden_size': 16, 'num_layers': 1, 'dropout_rate': 0.4136716511502754, 'learning_rate': 0.004476390666167816, 'batch_size': 128}. Best is trial 6 with value: 0.06909781927242875.\n",
      "[I 2025-06-23 15:09:05,009] Trial 14 pruned. \n",
      "[I 2025-06-23 15:09:18,997] Trial 15 finished with value: 0.07792671024799347 and parameters: {'window_size': 44, 'hidden_size': 16, 'num_layers': 1, 'dropout_rate': 0.3886789163525597, 'learning_rate': 0.0013566571511143385, 'batch_size': 128}. Best is trial 6 with value: 0.06909781927242875.\n",
      "[I 2025-06-23 15:09:36,447] Trial 16 pruned. \n",
      "[I 2025-06-23 15:09:54,276] Trial 17 pruned. \n",
      "[I 2025-06-23 15:11:06,394] Trial 18 pruned. \n",
      "[I 2025-06-23 15:11:22,944] Trial 19 pruned. \n",
      "[I 2025-06-23 15:11:50,132] Trial 20 pruned. \n",
      "[I 2025-06-23 15:12:04,479] Trial 21 pruned. \n",
      "[I 2025-06-23 15:12:18,745] Trial 22 finished with value: 0.0852343961596489 and parameters: {'window_size': 35, 'hidden_size': 16, 'num_layers': 1, 'dropout_rate': 0.39098877816684996, 'learning_rate': 0.0011821396066787713, 'batch_size': 128}. Best is trial 6 with value: 0.06909781927242875.\n",
      "[I 2025-06-23 15:12:33,267] Trial 23 pruned. \n",
      "[I 2025-06-23 15:12:48,339] Trial 24 pruned. \n",
      "[I 2025-06-23 15:13:02,767] Trial 25 finished with value: 0.08334077894687653 and parameters: {'window_size': 48, 'hidden_size': 16, 'num_layers': 1, 'dropout_rate': 0.4195959289595312, 'learning_rate': 0.003003179881556939, 'batch_size': 128}. Best is trial 6 with value: 0.06909781927242875.\n",
      "[I 2025-06-23 15:13:37,821] Trial 26 pruned. \n",
      "[I 2025-06-23 15:14:49,487] Trial 27 pruned. \n",
      "[I 2025-06-23 15:15:06,291] Trial 28 pruned. \n",
      "[I 2025-06-23 15:15:28,950] Trial 29 pruned. \n",
      "[I 2025-06-23 15:15:47,659] Trial 30 finished with value: 0.06508411653339863 and parameters: {'window_size': 45, 'hidden_size': 16, 'num_layers': 1, 'dropout_rate': 0.28402691414344977, 'learning_rate': 0.0015741672867975924, 'batch_size': 64}. Best is trial 30 with value: 0.06508411653339863.\n",
      "[I 2025-06-23 15:16:10,636] Trial 31 pruned. \n",
      "[I 2025-06-23 15:16:30,830] Trial 32 pruned. \n",
      "[I 2025-06-23 15:16:51,470] Trial 33 pruned. \n",
      "[I 2025-06-23 15:17:12,784] Trial 34 finished with value: 0.07882517327864964 and parameters: {'window_size': 37, 'hidden_size': 16, 'num_layers': 1, 'dropout_rate': 0.34583557651630736, 'learning_rate': 0.00013195058794407142, 'batch_size': 64}. Best is trial 30 with value: 0.06508411653339863.\n",
      "[I 2025-06-23 15:17:52,091] Trial 35 pruned. \n",
      "[I 2025-06-23 15:19:21,248] Trial 36 pruned. \n",
      "[I 2025-06-23 15:19:57,014] Trial 37 finished with value: 0.07464205231517554 and parameters: {'window_size': 40, 'hidden_size': 16, 'num_layers': 1, 'dropout_rate': 0.3204483942611667, 'learning_rate': 0.00029751863268795105, 'batch_size': 32}. Best is trial 30 with value: 0.06508411653339863.\n",
      "[I 2025-06-23 15:20:37,032] Trial 38 pruned. \n",
      "[I 2025-06-23 15:21:14,303] Trial 39 pruned. \n",
      "[I 2025-06-23 15:21:58,289] Trial 40 pruned. \n",
      "[I 2025-06-23 15:22:32,714] Trial 41 finished with value: 0.05387159623205662 and parameters: {'window_size': 46, 'hidden_size': 16, 'num_layers': 1, 'dropout_rate': 0.3339518266703523, 'learning_rate': 0.00011005223509250962, 'batch_size': 32}. Best is trial 41 with value: 0.05387159623205662.\n",
      "[I 2025-06-23 15:23:08,853] Trial 42 finished with value: 0.061272792518138885 and parameters: {'window_size': 49, 'hidden_size': 16, 'num_layers': 1, 'dropout_rate': 0.2896919431659816, 'learning_rate': 0.00011333818176169478, 'batch_size': 32}. Best is trial 41 with value: 0.05387159623205662.\n",
      "[I 2025-06-23 15:23:43,791] Trial 43 pruned. \n",
      "[I 2025-06-23 15:24:20,162] Trial 44 finished with value: 0.07408661022782326 and parameters: {'window_size': 47, 'hidden_size': 16, 'num_layers': 1, 'dropout_rate': 0.32501393724313954, 'learning_rate': 0.00014360492633774805, 'batch_size': 32}. Best is trial 41 with value: 0.05387159623205662.\n",
      "[I 2025-06-23 15:24:56,996] Trial 45 finished with value: 0.05923478677868843 and parameters: {'window_size': 47, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.33601404291622444, 'learning_rate': 0.00014706053193951676, 'batch_size': 32}. Best is trial 41 with value: 0.05387159623205662.\n",
      "[I 2025-06-23 15:25:33,321] Trial 46 pruned. \n",
      "[I 2025-06-23 15:26:12,841] Trial 47 pruned. \n",
      "[I 2025-06-23 15:27:01,150] Trial 48 pruned. \n",
      "[I 2025-06-23 15:27:27,065] Trial 49 finished with value: 0.053856249898672104 and parameters: {'window_size': 52, 'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.2828817758899461, 'learning_rate': 0.00016751947484876313, 'batch_size': 64}. Best is trial 49 with value: 0.053856249898672104.\n",
      "[I 2025-06-23 15:28:02,512] Trial 50 pruned. \n",
      "[I 2025-06-23 15:28:28,549] Trial 51 finished with value: 0.07456743717193604 and parameters: {'window_size': 49, 'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.28853375683076016, 'learning_rate': 0.0001266586319060948, 'batch_size': 64}. Best is trial 49 with value: 0.053856249898672104.\n",
      "[I 2025-06-23 15:28:48,522] Trial 52 pruned. \n",
      "[I 2025-06-23 15:29:15,479] Trial 53 pruned. \n",
      "[I 2025-06-23 15:29:35,908] Trial 54 finished with value: 0.05999959073960781 and parameters: {'window_size': 45, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.2788734701462956, 'learning_rate': 0.00011606766602106952, 'batch_size': 64}. Best is trial 49 with value: 0.053856249898672104.\n",
      "[I 2025-06-23 15:29:56,052] Trial 55 finished with value: 0.062250273302197456 and parameters: {'window_size': 45, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.27130116993840375, 'learning_rate': 0.00011061116681494241, 'batch_size': 64}. Best is trial 49 with value: 0.053856249898672104.\n",
      "[I 2025-06-23 15:30:16,460] Trial 56 finished with value: 0.06007910333573818 and parameters: {'window_size': 42, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.26935722042732174, 'learning_rate': 0.0001126526919265946, 'batch_size': 64}. Best is trial 49 with value: 0.053856249898672104.\n",
      "[I 2025-06-23 15:30:55,452] Trial 57 pruned. \n",
      "[I 2025-06-23 15:31:22,095] Trial 58 pruned. \n",
      "[I 2025-06-23 15:32:34,019] Trial 59 pruned. \n",
      "[I 2025-06-23 15:33:10,065] Trial 60 pruned. \n",
      "[I 2025-06-23 15:33:34,763] Trial 61 pruned. \n",
      "[I 2025-06-23 15:33:54,548] Trial 62 pruned. \n",
      "[I 2025-06-23 15:34:14,439] Trial 63 finished with value: 0.048105536960065365 and parameters: {'window_size': 46, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.29893475000061553, 'learning_rate': 0.00013568398099816852, 'batch_size': 64}. Best is trial 63 with value: 0.048105536960065365.\n",
      "[I 2025-06-23 15:34:33,845] Trial 64 finished with value: 0.06831137090921402 and parameters: {'window_size': 47, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.35104195650055386, 'learning_rate': 0.00013488001057681856, 'batch_size': 64}. Best is trial 63 with value: 0.048105536960065365.\n",
      "[I 2025-06-23 15:35:00,593] Trial 65 pruned. \n",
      "[I 2025-06-23 15:35:20,451] Trial 66 pruned. \n",
      "[I 2025-06-23 15:35:57,731] Trial 67 pruned. \n",
      "[I 2025-06-23 15:36:17,437] Trial 68 finished with value: 0.06604451593011618 and parameters: {'window_size': 46, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.36581454688685544, 'learning_rate': 0.0002431117512256972, 'batch_size': 64}. Best is trial 63 with value: 0.048105536960065365.\n",
      "[I 2025-06-23 15:37:28,056] Trial 69 pruned. \n",
      "[I 2025-06-23 15:37:47,355] Trial 70 pruned. \n",
      "[I 2025-06-23 15:38:06,611] Trial 71 pruned. \n",
      "[I 2025-06-23 15:38:26,815] Trial 72 finished with value: 0.06020777113735676 and parameters: {'window_size': 46, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.3327113803113508, 'learning_rate': 0.00011816338810925457, 'batch_size': 64}. Best is trial 63 with value: 0.048105536960065365.\n",
      "[I 2025-06-23 15:38:50,827] Trial 73 pruned. \n",
      "[I 2025-06-23 15:39:18,077] Trial 74 pruned. \n",
      "[I 2025-06-23 15:39:42,116] Trial 75 finished with value: 0.06490551680326462 and parameters: {'window_size': 48, 'hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0.3854917018931152, 'learning_rate': 0.00020606628444315425, 'batch_size': 64}. Best is trial 63 with value: 0.048105536960065365.\n",
      "[I 2025-06-23 15:40:18,793] Trial 76 finished with value: 0.06736394638816516 and parameters: {'window_size': 46, 'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.30800004317814367, 'learning_rate': 0.00012719958104732352, 'batch_size': 32}. Best is trial 63 with value: 0.048105536960065365.\n",
      "[I 2025-06-23 15:40:39,681] Trial 77 pruned. \n",
      "[I 2025-06-23 15:41:16,771] Trial 78 pruned. \n",
      "[I 2025-06-23 15:41:36,536] Trial 79 pruned. \n",
      "[I 2025-06-23 15:42:13,921] Trial 80 finished with value: 0.06498471399148305 and parameters: {'window_size': 46, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.2866859939692836, 'learning_rate': 0.00013906189724109376, 'batch_size': 32}. Best is trial 63 with value: 0.048105536960065365.\n",
      "[I 2025-06-23 15:42:34,030] Trial 81 pruned. \n",
      "[I 2025-06-23 15:42:53,864] Trial 82 finished with value: 0.05803097411990166 and parameters: {'window_size': 41, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.3237677119959638, 'learning_rate': 0.00011425775735393408, 'batch_size': 64}. Best is trial 63 with value: 0.048105536960065365.\n",
      "[I 2025-06-23 15:43:13,076] Trial 83 finished with value: 0.06619687005877495 and parameters: {'window_size': 41, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.33491564539938545, 'learning_rate': 0.00011945228499731323, 'batch_size': 64}. Best is trial 63 with value: 0.048105536960065365.\n",
      "[I 2025-06-23 15:43:40,416] Trial 84 pruned. \n",
      "[I 2025-06-23 15:44:00,222] Trial 85 pruned. \n",
      "[I 2025-06-23 15:45:17,916] Trial 86 pruned. \n",
      "[I 2025-06-23 15:45:45,288] Trial 87 pruned. \n",
      "[I 2025-06-23 15:46:38,044] Trial 88 pruned. \n",
      "[I 2025-06-23 15:47:05,940] Trial 89 finished with value: 0.06507368385791779 and parameters: {'window_size': 44, 'hidden_size': 16, 'num_layers': 1, 'dropout_rate': 0.24128712917736156, 'learning_rate': 0.00014616979275761064, 'batch_size': 64}. Best is trial 63 with value: 0.048105536960065365.\n",
      "[I 2025-06-23 15:47:57,576] Trial 90 pruned. \n",
      "[I 2025-06-23 15:48:25,616] Trial 91 finished with value: 0.04132209112867713 and parameters: {'window_size': 45, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.281069729569854, 'learning_rate': 0.00011209278345837319, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 15:48:53,363] Trial 92 pruned. \n",
      "[I 2025-06-23 15:49:20,892] Trial 93 pruned. \n",
      "[I 2025-06-23 15:49:48,617] Trial 94 finished with value: 0.05818754807114601 and parameters: {'window_size': 42, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.28988880443888376, 'learning_rate': 0.00011283221264285399, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 15:50:16,530] Trial 95 pruned. \n",
      "[I 2025-06-23 15:50:44,517] Trial 96 pruned. \n",
      "[I 2025-06-23 15:51:12,399] Trial 97 pruned. \n",
      "[I 2025-06-23 15:51:40,799] Trial 98 pruned. \n",
      "[I 2025-06-23 15:52:12,139] Trial 99 pruned. \n",
      "[I 2025-06-23 15:52:40,690] Trial 100 pruned. \n",
      "[I 2025-06-23 15:53:32,312] Trial 101 pruned. \n",
      "[I 2025-06-23 15:53:59,882] Trial 102 pruned. \n",
      "[I 2025-06-23 15:54:22,018] Trial 103 pruned. \n",
      "[I 2025-06-23 15:54:48,229] Trial 104 pruned. \n",
      "[I 2025-06-23 15:55:33,258] Trial 105 pruned. \n",
      "[I 2025-06-23 15:56:01,183] Trial 106 pruned. \n",
      "[I 2025-06-23 15:57:36,844] Trial 107 pruned. \n",
      "[I 2025-06-23 15:57:57,541] Trial 108 pruned. \n",
      "[I 2025-06-23 15:58:42,638] Trial 109 pruned. \n",
      "[I 2025-06-23 15:59:10,204] Trial 110 pruned. \n",
      "[I 2025-06-23 15:59:37,047] Trial 111 pruned. \n",
      "[I 2025-06-23 16:00:04,306] Trial 112 pruned. \n",
      "[I 2025-06-23 16:00:30,152] Trial 113 finished with value: 0.04573593754321337 and parameters: {'window_size': 46, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.23500238337752788, 'learning_rate': 0.00010828310892635706, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:00:55,416] Trial 114 pruned. \n",
      "[I 2025-06-23 16:01:28,828] Trial 115 pruned. \n",
      "[I 2025-06-23 16:01:48,293] Trial 116 finished with value: 0.05540455970913172 and parameters: {'window_size': 46, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.18151059798633756, 'learning_rate': 0.0001473217752001836, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:02:11,583] Trial 117 pruned. \n",
      "[I 2025-06-23 16:02:34,010] Trial 118 pruned. \n",
      "[I 2025-06-23 16:02:54,270] Trial 119 finished with value: 0.060907253374656044 and parameters: {'window_size': 39, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.21366221916655384, 'learning_rate': 0.00021830768254908932, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:03:14,452] Trial 120 pruned. \n",
      "[I 2025-06-23 16:03:40,995] Trial 121 finished with value: 0.054826569433013596 and parameters: {'window_size': 39, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.21018743854608998, 'learning_rate': 0.00013193519230838175, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:04:03,330] Trial 122 pruned. \n",
      "[I 2025-06-23 16:04:23,210] Trial 123 pruned. \n",
      "[I 2025-06-23 16:04:43,458] Trial 124 pruned. \n",
      "[I 2025-06-23 16:05:08,876] Trial 125 finished with value: 0.05819382146000862 and parameters: {'window_size': 41, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.2056485213098366, 'learning_rate': 0.0001205883415810876, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:05:36,406] Trial 126 pruned. \n",
      "[I 2025-06-23 16:05:59,489] Trial 127 pruned. \n",
      "[I 2025-06-23 16:06:27,798] Trial 128 pruned. \n",
      "[I 2025-06-23 16:06:56,599] Trial 129 pruned. \n",
      "[I 2025-06-23 16:07:24,605] Trial 130 pruned. \n",
      "[I 2025-06-23 16:07:50,303] Trial 131 finished with value: 0.04869414493441582 and parameters: {'window_size': 45, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.17367730131523695, 'learning_rate': 0.00011703934416125084, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:08:17,239] Trial 132 pruned. \n",
      "[I 2025-06-23 16:08:44,034] Trial 133 pruned. \n",
      "[I 2025-06-23 16:09:10,097] Trial 134 pruned. \n",
      "[I 2025-06-23 16:09:35,589] Trial 135 pruned. \n",
      "[I 2025-06-23 16:11:05,726] Trial 136 pruned. \n",
      "[I 2025-06-23 16:11:31,089] Trial 137 pruned. \n",
      "[I 2025-06-23 16:11:56,963] Trial 138 finished with value: 0.05939057096838951 and parameters: {'window_size': 39, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.17371741683592112, 'learning_rate': 0.00010048401194157518, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:12:22,359] Trial 139 finished with value: 0.056646532689531646 and parameters: {'window_size': 39, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.158049807543612, 'learning_rate': 0.0001006759625723536, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:12:45,994] Trial 140 pruned. \n",
      "[I 2025-06-23 16:13:11,088] Trial 141 finished with value: 0.057657633597652115 and parameters: {'window_size': 39, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.14155566759606053, 'learning_rate': 0.000100539525014729, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:13:36,873] Trial 142 pruned. \n",
      "[I 2025-06-23 16:14:02,833] Trial 143 pruned. \n",
      "[I 2025-06-23 16:14:26,313] Trial 144 finished with value: 0.04374327712381879 and parameters: {'window_size': 40, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.13697285873125464, 'learning_rate': 0.00012203928662681595, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:14:49,906] Trial 145 finished with value: 0.05004445952363312 and parameters: {'window_size': 40, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.14004276806567398, 'learning_rate': 0.00014999212787861048, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:15:15,886] Trial 146 finished with value: 0.05595171203215917 and parameters: {'window_size': 40, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.13578718766194237, 'learning_rate': 0.00012037387637425516, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:15:41,482] Trial 147 pruned. \n",
      "[I 2025-06-23 16:16:07,213] Trial 148 pruned. \n",
      "[I 2025-06-23 16:16:32,983] Trial 149 finished with value: 0.04986861410240332 and parameters: {'window_size': 40, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.12594533847044473, 'learning_rate': 0.00011852620113752785, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:16:59,982] Trial 150 pruned. \n",
      "[I 2025-06-23 16:17:25,414] Trial 151 finished with value: 0.05876243052383264 and parameters: {'window_size': 40, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.12533758487762386, 'learning_rate': 0.00011198731512165155, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:17:51,377] Trial 152 pruned. \n",
      "[I 2025-06-23 16:18:16,772] Trial 153 pruned. \n",
      "[I 2025-06-23 16:18:45,627] Trial 154 pruned. \n",
      "[I 2025-06-23 16:19:11,456] Trial 155 pruned. \n",
      "[I 2025-06-23 16:19:36,999] Trial 156 pruned. \n",
      "[I 2025-06-23 16:20:02,883] Trial 157 finished with value: 0.05305027961730957 and parameters: {'window_size': 39, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.16163564753622792, 'learning_rate': 0.00011819619282236229, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:20:28,745] Trial 158 pruned. \n",
      "[I 2025-06-23 16:20:55,588] Trial 159 pruned. \n",
      "[I 2025-06-23 16:21:14,699] Trial 160 pruned. \n",
      "[I 2025-06-23 16:21:41,000] Trial 161 finished with value: 0.05707863594094912 and parameters: {'window_size': 39, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.14815304896882103, 'learning_rate': 0.00011312815564341689, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:22:06,488] Trial 162 pruned. \n",
      "[I 2025-06-23 16:22:31,678] Trial 163 finished with value: 0.05611182718227307 and parameters: {'window_size': 40, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.1326072141997254, 'learning_rate': 0.00010777496328872887, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:22:57,681] Trial 164 pruned. \n",
      "[I 2025-06-23 16:23:23,586] Trial 165 pruned. \n",
      "[I 2025-06-23 16:23:46,413] Trial 166 finished with value: 0.05835710714260737 and parameters: {'window_size': 40, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.10737643329600925, 'learning_rate': 0.00012002389555328358, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:24:06,135] Trial 167 pruned. \n",
      "[I 2025-06-23 16:24:31,456] Trial 168 pruned. \n",
      "[I 2025-06-23 16:24:57,449] Trial 169 pruned. \n",
      "[I 2025-06-23 16:26:31,273] Trial 170 pruned. \n",
      "[I 2025-06-23 16:26:56,841] Trial 171 pruned. \n",
      "[I 2025-06-23 16:27:23,035] Trial 172 pruned. \n",
      "[I 2025-06-23 16:27:49,036] Trial 173 pruned. \n",
      "[I 2025-06-23 16:28:15,186] Trial 174 pruned. \n",
      "[I 2025-06-23 16:28:41,013] Trial 175 pruned. \n",
      "[I 2025-06-23 16:29:06,768] Trial 176 finished with value: 0.04831142475207647 and parameters: {'window_size': 40, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.1318987455688575, 'learning_rate': 0.00010036838241534237, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:29:34,148] Trial 177 pruned. \n",
      "[I 2025-06-23 16:29:59,555] Trial 178 finished with value: 0.04926966316998005 and parameters: {'window_size': 40, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.14020897383654796, 'learning_rate': 0.00010172722500225326, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:30:25,267] Trial 179 pruned. \n",
      "[I 2025-06-23 16:30:50,510] Trial 180 pruned. \n",
      "[I 2025-06-23 16:31:13,760] Trial 181 pruned. \n",
      "[I 2025-06-23 16:31:33,382] Trial 182 finished with value: 0.05409363843500614 and parameters: {'window_size': 39, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.13499332022017882, 'learning_rate': 0.00010070987540699944, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:31:59,137] Trial 183 pruned. \n",
      "[I 2025-06-23 16:32:24,521] Trial 184 pruned. \n",
      "[I 2025-06-23 16:32:49,721] Trial 185 pruned. \n",
      "[I 2025-06-23 16:33:15,382] Trial 186 pruned. \n",
      "[I 2025-06-23 16:33:38,335] Trial 187 pruned. \n",
      "[I 2025-06-23 16:33:58,390] Trial 188 pruned. \n",
      "[I 2025-06-23 16:34:17,044] Trial 189 pruned. \n",
      "[I 2025-06-23 16:34:42,012] Trial 190 finished with value: 0.04723077733069658 and parameters: {'window_size': 40, 'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.16182511067380878, 'learning_rate': 0.00011823934470199442, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:35:07,263] Trial 191 finished with value: 0.054614389315247536 and parameters: {'window_size': 40, 'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.16156967050429571, 'learning_rate': 0.00011741283193323023, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:35:32,019] Trial 192 finished with value: 0.05118248922129472 and parameters: {'window_size': 40, 'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.16792520111491405, 'learning_rate': 0.0001296432533246245, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:35:57,084] Trial 193 pruned. \n",
      "[I 2025-06-23 16:36:22,322] Trial 194 finished with value: 0.05709304288029671 and parameters: {'window_size': 42, 'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.17542781446965366, 'learning_rate': 0.00015951509409244975, 'batch_size': 64}. Best is trial 91 with value: 0.04132209112867713.\n",
      "[I 2025-06-23 16:36:52,302] Trial 195 pruned. \n",
      "[I 2025-06-23 16:37:17,386] Trial 196 pruned. \n",
      "[I 2025-06-23 16:37:42,740] Trial 197 pruned. \n",
      "[I 2025-06-23 16:38:05,212] Trial 198 pruned. \n",
      "[I 2025-06-23 16:38:28,974] Trial 199 pruned. \n",
      "\n",
      "Optimización de hiperparámetros completada.\n",
      "Mejores hiperparámetros encontrados:\n",
      "{'window_size': 45, 'hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.281069729569854, 'learning_rate': 0.00011209278345837319, 'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "# --- Ejecutar el estudio de Optuna ---\n",
    "study = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner())\n",
    "study.optimize(objective, n_trials=200, show_progress_bar=True)\n",
    "\n",
    "print(\"\\nOptimización de hiperparámetros completada.\")\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "best_params = study.best_params\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85ecc882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando entrenamiento del modelo final...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9eb051547e40e98d7d6fd7de005f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 0.394250\n",
      "Epoch [20/200], Loss: 0.334029\n",
      "Epoch [30/200], Loss: 0.309835\n",
      "Epoch [40/200], Loss: 0.314164\n",
      "Epoch [50/200], Loss: 0.300228\n",
      "Epoch [60/200], Loss: 0.290639\n",
      "Epoch [70/200], Loss: 0.294850\n",
      "Epoch [80/200], Loss: 0.278476\n",
      "Epoch [90/200], Loss: 0.272100\n",
      "Epoch [100/200], Loss: 0.270139\n",
      "Epoch [110/200], Loss: 0.265394\n",
      "Epoch [120/200], Loss: 0.261844\n",
      "Epoch [130/200], Loss: 0.254873\n",
      "Epoch [140/200], Loss: 0.247764\n",
      "Epoch [150/200], Loss: 0.233945\n",
      "Epoch [160/200], Loss: 0.234790\n",
      "Epoch [170/200], Loss: 0.232264\n",
      "Epoch [180/200], Loss: 0.221984\n",
      "Epoch [190/200], Loss: 0.227818\n",
      "Epoch [200/200], Loss: 0.223093\n",
      "Entrenamiento final completado.\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Pérdida de Entrenamiento (MSE)",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200
         ],
         "y": [
          0.9082056523538103,
          0.7894122098006454,
          0.6775248173405143,
          0.591031130622415,
          0.5073014731500664,
          0.46142318231218,
          0.42665647846810956,
          0.4012659259286581,
          0.3989934430402868,
          0.3942498351429023,
          0.3738575113170287,
          0.3751096649497163,
          0.3647262521234213,
          0.35305694271536436,
          0.34790293317215115,
          0.3417551336335201,
          0.33615406003652837,
          0.3390141395377178,
          0.3402961808092454,
          0.33402937504590724,
          0.326468752441453,
          0.31842141379328337,
          0.3307655325122908,
          0.32546621531832454,
          0.32039781995848116,
          0.32180604484735753,
          0.3283086898280125,
          0.31884748298747867,
          0.3260047254609127,
          0.30983543717393686,
          0.32385383926185907,
          0.31432843442056696,
          0.3314693751288395,
          0.3071217700546863,
          0.31390784067266125,
          0.3153487692276637,
          0.30729056135112165,
          0.3145275209464279,
          0.3127467220320421,
          0.314163956425938,
          0.3096751629137525,
          0.3058677099499048,
          0.30583923485349207,
          0.3007344594773124,
          0.3011518009737426,
          0.3045619901488809,
          0.30445148313746734,
          0.30512089852024527,
          0.29930762040848824,
          0.3002275549897961,
          0.30056366499732523,
          0.30499740032588735,
          0.30127964840800153,
          0.2947353083713382,
          0.2967119544160132,
          0.2964202241570342,
          0.29782651569329055,
          0.2942091650238224,
          0.294833534488491,
          0.2906393852888369,
          0.29554926238807977,
          0.30017408231894177,
          0.2905089302974589,
          0.2981652320892203,
          0.28620581153561087,
          0.2915553199309929,
          0.28466569530028923,
          0.29256001231717127,
          0.28951851672985973,
          0.2948503351094676,
          0.2978496154149373,
          0.2923876257503734,
          0.28641723797601815,
          0.28745924520726296,
          0.2794536398906334,
          0.2909007659729789,
          0.2830558318425627,
          0.2841600395885168,
          0.2809203591416864,
          0.27847567288314595,
          0.27856747557719547,
          0.28305169677033143,
          0.27984626737295415,
          0.27247049250439104,
          0.2804733193388172,
          0.27621913745122795,
          0.27954569721923156,
          0.2782922381279515,
          0.276582568007357,
          0.272100315812756,
          0.2718436083957261,
          0.2784903242307551,
          0.27693864732396367,
          0.26726704368404314,
          0.27057654805043163,
          0.2743621538667118,
          0.2704990774977441,
          0.2676379522856544,
          0.263703132669131,
          0.2701393690179376,
          0.26489579297748267,
          0.26550450336699394,
          0.26544078454083087,
          0.2617502031373043,
          0.2642049636034405,
          0.25884781690204844,
          0.26587429788767125,
          0.2668072175161511,
          0.25745666815954094,
          0.2653939932876942,
          0.2607909322661512,
          0.2624964277241744,
          0.2603404684101834,
          0.2532685593354936,
          0.25560904937047585,
          0.2546356895975038,
          0.2578791166637458,
          0.2540106703253353,
          0.2563622123470493,
          0.2618443076224888,
          0.25645938515663147,
          0.2567463993441825,
          0.2566812497143652,
          0.25182538990880926,
          0.2463448827757555,
          0.25032325673337075,
          0.2517672952483682,
          0.24722091064733617,
          0.24736479450674617,
          0.25487300607503627,
          0.2514270545513022,
          0.24625611685070337,
          0.24806360272215863,
          0.24659515245288027,
          0.2493645747502645,
          0.25579145813689513,
          0.2475692098047219,
          0.24969012757726744,
          0.2406010404229164,
          0.24776402641745174,
          0.2449512807469742,
          0.24317251175057655,
          0.2406541126615861,
          0.24719752590445912,
          0.24060020142910526,
          0.24364415030269063,
          0.24507901802951215,
          0.23783746405559428,
          0.2367427730384995,
          0.23394477849497514,
          0.24369445034101897,
          0.23550114035606384,
          0.24543343908062168,
          0.23539825704167872,
          0.232798831866068,
          0.2332600949733865,
          0.23328842135036693,
          0.23706339080544078,
          0.23687922004975526,
          0.23478958492769914,
          0.23131335658185623,
          0.2354853902669514,
          0.23395472151391647,
          0.2331497822614277,
          0.23195880023287793,
          0.23303556829398753,
          0.2318047602094856,
          0.23144516173531027,
          0.23359212732198192,
          0.2322644562113519,
          0.23359385132789612,
          0.22693857068524642,
          0.22719584741428786,
          0.22957142895343258,
          0.22839738764599257,
          0.23385573602190204,
          0.22544970830865935,
          0.23044812460156047,
          0.23021339873472849,
          0.22198416351103314,
          0.22653538120143554,
          0.22162623601216896,
          0.22567987003747156,
          0.22635740158604642,
          0.2235183476233015,
          0.22651325093180524,
          0.22515496275588578,
          0.2221624760651121,
          0.2241610222879578,
          0.22781842450300852,
          0.22621241489461824,
          0.2176230419792381,
          0.22814901611384222,
          0.22548685544261746,
          0.21879850649366192,
          0.22137766755094715,
          0.22360346977617226,
          0.2181927076741761,
          0.2260542171550732,
          0.22309319821058535
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Curva de Pérdida del Modelo Final"
        },
        "xaxis": {
         "title": {
          "text": "Época"
         }
        },
        "yaxis": {
         "title": {
          "text": "Error Cuadrático Medio (MSE)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Preparar datos combinados (Train + Val) ---\n",
    "final_train_df = df_train_val.copy()\n",
    "\n",
    "# Aplicar mapeos categóricos\n",
    "for col, mapping in cat_mappings.items():\n",
    "    final_train_df[col] = final_train_df[col].cat.codes\n",
    "\n",
    "# Re-escalar variables numéricas con todos los datos (2018-2021)\n",
    "final_scaler = StandardScaler()\n",
    "final_scaler.fit(final_train_df[numerical_features_to_scale])\n",
    "final_train_df.loc[:, numerical_features_to_scale] = final_scaler.transform(final_train_df[numerical_features_to_scale])\n",
    "\n",
    "# --- Crear secuencias con los mejores parámetros ---\n",
    "best_window_size = best_params['window_size']\n",
    "X_final_train_seq, y_final_train_seq = create_sequences(final_train_df, best_window_size, target_col, categorical_cols, numerical_cols)\n",
    "\n",
    "X_final_train_tensor = torch.tensor(X_final_train_seq, dtype=torch.float32)\n",
    "y_final_train_tensor = torch.tensor(y_final_train_seq, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# --- DataLoader final ---\n",
    "final_train_dataset = TensorDataset(X_final_train_tensor, y_final_train_tensor)\n",
    "final_train_loader = DataLoader(final_train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "\n",
    "# --- Instanciar y entrenar el modelo final ---\n",
    "final_model = GRUModel(\n",
    "    embedding_sizes=embedding_sizes,\n",
    "    n_continuous=n_continuous,\n",
    "    hidden_size=best_params['hidden_size'],\n",
    "    num_layers=best_params['num_layers'],\n",
    "    dropout_rate=best_params['dropout_rate']\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=best_params['learning_rate'])\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Bucle de entrenamiento final\n",
    "num_epochs_final = 200 # Entrenar por más épocas en el modelo final\n",
    "train_losses = []\n",
    "\n",
    "print(\"\\nIniciando entrenamiento del modelo final...\")\n",
    "for epoch in tqdm(range(num_epochs_final)):\n",
    "    final_model.train()\n",
    "    epoch_loss = 0\n",
    "    for sequences, labels in final_train_loader:\n",
    "        sequences, labels = sequences.to(device), labels.to(device)\n",
    "        \n",
    "        x_cat = sequences[:, :, cat_indices].long()\n",
    "        x_cont = sequences[:, :, num_indices].float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(x_cat, x_cont)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_epoch_loss = epoch_loss / len(final_train_loader)\n",
    "    train_losses.append(avg_epoch_loss)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs_final}], Loss: {avg_epoch_loss:.6f}')\n",
    "\n",
    "print(\"Entrenamiento final completado.\")\n",
    "\n",
    "# --- Graficar curva de pérdida ---\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=list(range(1, num_epochs_final + 1)), \n",
    "    y=train_losses, \n",
    "    mode='lines',\n",
    "    name='Pérdida de Entrenamiento (MSE)'\n",
    "))\n",
    "fig.update_layout(\n",
    "    title='Curva de Pérdida del Modelo Final',\n",
    "    xaxis_title='Época',\n",
    "    yaxis_title='Error Cuadrático Medio (MSE)',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "679118b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando generación de pronósticos autorregresivos para 2022...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e0487605f745c2a13e2073f0e100b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pronosticando por Barrio:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\AppData\\Local\\Temp\\ipykernel_660\\3465917340.py:32: UserWarning:\n",
      "\n",
      "Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pronósticos para 2022 generados.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nIniciando generación de pronósticos autorregresivos para 2022...\")\n",
    "\n",
    "# Preparar el dataframe de entrada para el pronóstico\n",
    "df_forecast_proc = df_forecast_inputs.copy()\n",
    "for col, mapping in cat_mappings.items():\n",
    "    # Asegurarse de que el tipo sea category antes de usar .cat.codes\n",
    "    df_forecast_proc[col] = pd.Categorical(df_forecast_proc[col], categories=mapping.keys())\n",
    "    df_forecast_proc[col] = df_forecast_proc[col].cat.codes\n",
    "    \n",
    "df_forecast_proc.loc[:, numerical_features_to_scale] = final_scaler.transform(df_forecast_proc[numerical_features_to_scale])\n",
    "\n",
    "# --- **CORRECCIÓN**: Crear un mapeo inverso para obtener las categorías originales a partir de los códigos ---\n",
    "reverse_cat_mappings = {\n",
    "    col: {code: cat for cat, code in mapping.items()}\n",
    "    for col, mapping in cat_mappings.items()\n",
    "}\n",
    "\n",
    "predictions = []\n",
    "final_model.eval()\n",
    "\n",
    "# Bucle por cada barrio. El 'id_bar_code' que devuelve groupby es el código numérico (0, 1, 2...)\n",
    "for id_bar_code, group in tqdm(df_forecast_proc.groupby('id_bar'), desc=\"Pronosticando por Barrio\"):\n",
    "    \n",
    "    # Obtener la última secuencia de datos reales (final de 2021)\n",
    "    history = group[group['anio'] == 2021].iloc[-best_window_size:]\n",
    "    \n",
    "    # Bucle por cada semana de 2022\n",
    "    for week in range(1, 53):\n",
    "        \n",
    "        # Preparar la secuencia de entrada\n",
    "        input_seq_df = history[categorical_cols + numerical_cols]\n",
    "        input_seq_tensor = torch.tensor([input_seq_df.values], dtype=torch.float32).to(device)\n",
    "\n",
    "        # Separar en categóricas y continuas\n",
    "        x_cat = input_seq_tensor[:, :, cat_indices].long()\n",
    "        x_cont = input_seq_tensor[:, :, num_indices].float()\n",
    "\n",
    "        # Realizar la predicción\n",
    "        with torch.no_grad():\n",
    "            pred_scaled = final_model(x_cat, x_cont)\n",
    "\n",
    "        # Crear un array temporal para des-escalar solo la predicción\n",
    "        dummy_array = np.zeros((1, len(numerical_features_to_scale)))\n",
    "        target_idx_in_scaler = numerical_features_to_scale.index(target_col)\n",
    "        dummy_array[0, target_idx_in_scaler] = pred_scaled.item()\n",
    "        \n",
    "        # Des-escalar la predicción\n",
    "        pred_descaled = final_scaler.inverse_transform(dummy_array)[0, target_idx_in_scaler]\n",
    "        pred_descaled = max(0, int(round(pred_descaled))) # El dengue no puede ser negativo ni fraccionario\n",
    "\n",
    "        # Guardar la predicción\n",
    "        # --- **CORRECCIÓN**: Usar el mapeo inverso para una búsqueda directa ---\n",
    "        id_bar_original = reverse_cat_mappings['id_bar'][id_bar_code]\n",
    "        predictions.append({\n",
    "            'id_bar': id_bar_original,\n",
    "            'anio': 2022,\n",
    "            'semana': week,\n",
    "            'dengue': pred_descaled\n",
    "        })\n",
    "\n",
    "        # --- Actualización Autorregresiva ---\n",
    "        # Obtener las covariables conocidas para la semana que estamos prediciendo\n",
    "        next_step_features = group[(group['anio'] == 2022) & (group['semana'] == week)]\n",
    "        if next_step_features.empty:\n",
    "            # Si no hay datos para esa semana (poco probable), reutilizar la última conocida y actualizar la semana\n",
    "            next_step_features = history.iloc[-1:].copy()\n",
    "            next_step_features['semana'] = week\n",
    "        else:\n",
    "            next_step_features = next_step_features.copy()\n",
    "\n",
    "        # Reemplazar el valor de 'dengue' con nuestra predicción escalada\n",
    "        next_step_features.loc[:, target_col] = pred_scaled.item()\n",
    "\n",
    "        # Añadir el nuevo paso de tiempo al historial y eliminar el más antiguo\n",
    "        history = pd.concat([history.iloc[1:], next_step_features])\n",
    "\n",
    "print(\"Pronósticos para 2022 generados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94235576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archivo de predicciones guardado como: 'pronosticos_dengue_2022_20250623.csv'\n",
      "          id  dengue\n",
      "0  0_2022_01       2\n",
      "1  0_2022_02       2\n",
      "2  0_2022_03       2\n",
      "3  0_2022_04       2\n",
      "4  0_2022_05       2\n",
      "Número total de predicciones: 520\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Crear DataFrame con los resultados\n",
    "df_results = pd.DataFrame(predictions)\n",
    "\n",
    "# Crear la columna 'id' con el formato especificado\n",
    "df_results['id'] = df_results.apply(\n",
    "    lambda row: f\"{row['id_bar']}_{row['anio']}_{row['semana']:02d}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Seleccionar y ordenar las columnas finales\n",
    "df_submission = df_results[['id', 'dengue']]\n",
    "\n",
    "# Guardar en archivo CSV\n",
    "fecha_actual = datetime.now().strftime('%Y%m%d')\n",
    "output_filename = f'pronosticos_dengue_2022_{fecha_actual}.csv'\n",
    "df_submission.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"\\nArchivo de predicciones guardado como: '{output_filename}'\")\n",
    "print(df_submission.head())\n",
    "print(f\"Número total de predicciones: {len(df_submission)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
